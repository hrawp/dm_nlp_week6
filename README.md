# Web Scraping and NLP with Requests, BeautifulSoup, and spaCy

In this project we worked through reading in an article and then using NLP to count lemmas and tokens.  I counted the top 5 of each.  Then I ran that against a scoring function.  This calucations how many lemmas or tokens were in each setence then divided by the number of words.  This scoring was completed against each setence of the article.  Then I plotted the results in a histogram for both tokens and lemmas.


Complete the tasks in the Python Notebook in this repository.
Make sure to add and push the pkl or text file of your scraped html (this is specified in the notebook)

## Rubric

* (Question 1) Article html stored in separate file that is committed and pushed: 1 pt
* (Question 2) Article text is correct: 1 pt
* (Question 3) Correct (or equivalent in the case of multiple tokens with same frequency) tokens printed: 1 pt
* (Question 4) Correct (or equivalent in the case of multiple lemmas with same frequency) lemmas printed: 1 pt
* (Question 5) Correct scores for first sentence printed: 2 pts (1 / function)
* (Question 6) Histogram shown with appropriate labelling: 1 pt
* (Question 7) Histogram shown with appropriate labelling: 1 pt
* (Question 8) Thoughtful answer provided: 1 pt
